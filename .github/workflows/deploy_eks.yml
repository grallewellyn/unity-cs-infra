name: EKS Deployment
env:
  EKSClusterRegion: us-west-2
  EKSKubeProxyVersion: latest
  EKSCoreDNSVersion: latest
  EKSEBSCSIVersion: latest
# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the main branch
  # push:
  #   branches: [ ucs-template ]
  # pull_request:
  #   branches: [ ucs-template ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
    branches: [ main ]
    inputs:
      distinct_id:
      KEY:
        description: 'Access Key ID'
        required: false
        type: string
        default: ''
      SECRET:
        description: 'Access Secret Key ID'
        required: false
        type: string
        default: ''
      TOKEN:
        description: 'AWS Session Token'
        required: false
        type: string
        default: ''
      META:
        description: 'metadata description'
        required: true
        type: string
      AWSCONNECTION:
        description: 'Method of AWS connection'
        required: true
        type: choice
        default: 'oidc'
        options:
        - oidc
        - keys
        - iam
      DEPLOYMENTPROJECT:
        description: 'Deployment Project'
        required: true 
        type: choice
        default: 'UNITY'
        options: 
        - UNITY
        - SIPS
      DEPLOYMENTSTAGE:
        description: 'Deployment Target'
        required: true 
        type: choice
        default: 'DEV'
        options: 
        - DEV
        - TEST
        - OPS
        - SIPS
permissions:
  id-token: write # required to use OIDC authentication
  contents: read # required to checkout the code from the repo

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  workflow:
    runs-on: ubuntu-latest
    steps:
      - name: echo distinct ID ${{ github.event.inputs.distinct_id }}
        run: echo ${{ github.event.inputs.distinct_id }}
  # This workflow contains a single job called "deployment"
  deployment:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Set up current working directory with the repo contents
      - uses: actions/checkout@v3
      
      - name: Set env vars
        run: |
          if [ ${{ INPUTS.DEPLOYMENTSTAGE }} == "DEV" ];
          then
            echo "EKSClusterVersion=${{ env.MCP_DEV_EKSCLUSTERVERSION }}" >> $GITHUB_ENV
            echo "EKSClusterAMI=${{ env.MCP_DEV_EKSCLUSTERAMI }}" >> $GITHUB_ENV
            echo "EKSSecurityGroup=${{ MCP_DEV_EKSSECURITYGROUP }}" >> $GITHUB_ENV
            echo "EKSSharedNodeSecurityGroup=${{ MCP_DEV_EKSSHAREDNODESECURITYGROUP }}" >> $GITHUB_ENV
            echo "EKSSubnetConfigA=${{ MCP_DEV_EKSSUBNETCONFIGA }}" >> $GITHUB_ENV
            echo "EKSSubnetConfigB=${{ MCP_DEV_EKSSUBNETCONFIGB }}" >> $GITHUB_ENV
            echo "EKSInstanceRoleArn=${{ MCP_DEV_EKSINSTANCEROLEARN }}" >> $GITHUB_ENV
            echo "EKSServiceArn=${{ MCP_DEV_EKSSERVICEARN }}" >> $GITHUB_ENV
          elif [ ${{ INPUTS.DEPLOYMENTSTAGE }} == "TEST" ];
          then
            echo "EKSClusterVersion=${{ env.MCP_TEST_EKSCLUSTERVERSION }}" >> $GITHUB_ENV
            echo "EKSClusterAMI=${{ env.MCP_TEST_EKSCLUSTERAMI }}" >> $GITHUB_ENV
            echo "EKSSecurityGroup=${{ MCP_TEST_EKSSECURITYGROUP }}" >> $GITHUB_ENV
            echo "EKSSharedNodeSecurityGroup=${{ MCP_TEST_EKSSHAREDNODESECURITYGROUP }}" >> $GITHUB_ENV
            echo "EKSSubnetConfigA=${{ MCP_TEST_EKSSUBNETCONFIGA }}" >> $GITHUB_ENV
            echo "EKSSubnetConfigB=${{ MCP_TEST_EKSSUBNETCONFIGB }}" >> $GITHUB_ENV
            echo "EKSInstanceRoleArn=${{ MCP_TEST_EKSINSTANCEROLEARN }}" >> $GITHUB_ENV
            echo "EKSServiceArn=${{ MCP_TEST_EKSSERVICEARN }}" >> $GITHUB_ENV
          fi
      # Configure AWS Credentials through OIDC
      - name: Configure AWS credentials
        if: ${{ INPUTS.AWSCONNECTION == 'oidc' }}
        uses: aws-actions/configure-aws-credentials@v1
        with:
          #role-to-assume: ${{ secrets.OIDC_ROLE }}
          role-to-assume: ${{ secrets[format('OIDC_{0}_ROLE', INPUTS.DEPLOYMENTSTAGE)] }}
          aws-region: ${{ secrets.AWS_REGION }}

      # Install eksctl to launch EKS
      - name: Install eksctl
        run: |
         curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp && \
         sudo mv /tmp/eksctl /usr/local/bin && \
         eksctl version

      - name: Install Unity Transformer
        run: |
          curl --silent --location https://github.com/unity-sds/unity-cs-terraform-transformer/releases/download/0.1.12-Alpha/unity-cs-terraform-transformer-0.1.12-Alpha-linux-amd64.tar.gz | tar xz -C /tmp
          sudo mv /tmp/unity-cs-terraform-transformer /usr/local/bin

      # Render template
      - name: Render Template
        run: |
          export owner=$(echo ${{ inputs.META }} | jq -r .owner)
          export cluster=$(echo ${{ inputs.META }} | jq -r .clustername)
          export minnodes=$(echo ${{ inputs.META }} | jq -r .nodegroups.group1.nodecount)
          export maxnodes=$(echo ${{ inputs.META }} | jq -r .nodegroups.group1.nodecount)
          export desirednodes=$(echo ${{ inputs.META }} | jq -r .nodegroups.group1.nodecount)
          export instancetype=$(echo ${{ inputs.META }} | jq -r .nodegroups.group1.instancetype)
          unity-cs-terraform-transformer eks --clustername ${cluster} --owner ${owner} --managenodegroups defaultgroup,${minnodes},${maxnodes},${desirednodes},m5.xlarge --instancetype ${instancetype} --projectname ${owner} --servicename ${owner} > /tmp/eksctl-config.yaml
          cat /tmp/eksctl-config.yaml
      # Launch EKS
      - name: Launch EKS cluster
        run: |
          if [ -z "$inputs.KEY" ]
          then
              export AWS_ACCESS_KEY_ID: ${{ inputs.KEY }}
              export AWS_SECRET_ACCESS_KEY: ${{ inputs.SECRET }}
              export AWS_SESSION_TOKEN: ${{ inputs.TOKEN }}
              export AWS_PAGER: ""
          fi
          export cluster=$(echo ${{ inputs.META }} | jq -r .clustername)
          eksctl create cluster -f /tmp/eksctl-config.yaml
          aws eks update-kubeconfig --region us-west-2 --name $cluster
          kubectl patch storageclass gp2 -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"false"}}}'
          #aws ssm put-parameter --name /${{ inputs.CLUSTERNAME }}/eks --value ${{ inputs.CLUSTERNAME }} --tags=Key=project,Value=u-cs --type String
